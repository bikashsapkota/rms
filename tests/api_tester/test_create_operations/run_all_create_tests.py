#!/usr/bin/env python3
"""
Run All Create Operations Tests

Orchestrates execution of all create operation test suites.
Provides comprehensive testing of all POST endpoints in the RMS API.
"""

import sys
import asyncio
import time
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from tests.api_tester.shared.utils import APITestClient, APITestHelper, TestResults


class CreateOperationsOrchestrator:
    """Orchestrates all create operation tests"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.overall_results = TestResults()
        self.test_modules = []
        
    def print_header(self, title: str, emoji: str = "‚ûï"):
        """Print formatted section header"""
        print(f"\n{'=' * 60}")
        print(f"{emoji}  {title}")
        print(f"{'=' * 60}")
        
    def print_step(self, step: str, status: str = "RUNNING"):
        """Print test step with status"""
        status_icons = {
            "RUNNING": "üîÑ",
            "SUCCESS": "‚úÖ",
            "FAILED": "‚ùå",
            "SKIPPED": "‚è≠Ô∏è"
        }
        icon = status_icons.get(status, "üîÑ")
        print(f"{icon} {step}")
        
    async def run_test_module(self, module_name: str, description: str) -> bool:
        """Run a specific test module"""
        
        self.print_step(f"{description}", "RUNNING")
        
        try:
            import subprocess
            
            # Run the test module
            script_path = Path(__file__).parent / module_name
            
            if not script_path.exists():
                self.print_step(f"{description} - Script not found", "FAILED")
                return False
                
            start_time = time.time()
            result = subprocess.run(
                [sys.executable, str(script_path), "--base-url", self.base_url],
                capture_output=True,
                text=True,
                cwd=project_root
            )
            
            execution_time = time.time() - start_time
            
            if result.returncode == 0:
                self.print_step(f"{description} completed ({execution_time:.1f}s)", "SUCCESS")
                
                # Extract success information from output
                output_lines = result.stdout.split('\n')
                success_lines = [line for line in output_lines if '‚úÖ' in line or 'passed successfully' in line]
                for line in success_lines[-2:]:  # Show last 2 success lines
                    if line.strip():
                        print(f"   {line.strip()}")
                        
                # Store test results
                self.test_modules.append({
                    "module": module_name,
                    "description": description,
                    "success": True,
                    "execution_time": execution_time,
                    "output": result.stdout
                })
                
                return True
                
            else:
                self.print_step(f"{description} failed", "FAILED")
                
                # Show error details
                if result.stderr:
                    error_lines = result.stderr.strip().split('\n')
                    for line in error_lines[-3:]:  # Show last 3 error lines
                        if line.strip():
                            print(f"   Error: {line.strip()}")
                    
                # Store failure results
                self.test_modules.append({
                    "module": module_name,
                    "description": description,
                    "success": False,
                    "execution_time": execution_time,
                    "stdout": result.stdout,
                    "stderr": result.stderr,
                    "return_code": result.returncode
                })
                
                return False
                
        except Exception as e:
            self.print_step(f"{description} error: {e}", "FAILED")
            
            self.test_modules.append({
                "module": module_name,
                "description": description,
                "success": False,
                "execution_time": 0,
                "error": str(e)
            })
            
            return False
            
    async def run_all_create_tests(self) -> bool:
        """Run all create operation test modules"""
        
        # Define test modules to run
        test_modules = [
            ("test_restaurant_setup.py", "Restaurant Setup & Application Process"),
            ("test_user_creation.py", "User Creation & Role Management"),
            ("test_menu_creation.py", "Menu Creation & Data Validation")
        ]
        
        overall_success = True
        
        for module_name, description in test_modules:
            try:
                success = await self.run_test_module(module_name, description)
                if not success:
                    overall_success = False
                    
            except Exception as e:
                self.print_step(f"{description} failed with error: {e}", "FAILED")
                overall_success = False
                
            # Add delay between test modules
            await asyncio.sleep(1.0)
            
        return overall_success
        
    def print_comprehensive_summary(self):
        """Print comprehensive summary of all create tests"""
        
        self.print_header("Create Operations Test Summary", "üìä")
        
        total_modules = len(self.test_modules)
        successful_modules = sum(1 for module in self.test_modules if module["success"])
        
        print(f"\nüéØ Overall Results:")
        print(f"   Test Modules: {total_modules}")
        print(f"   Successful: {successful_modules}")
        print(f"   Failed: {total_modules - successful_modules}")
        print(f"   Success Rate: {(successful_modules/total_modules)*100:.1f}%")
        
        # Calculate total execution time
        total_time = sum(module.get("execution_time", 0) for module in self.test_modules)
        print(f"   Total Execution Time: {total_time:.2f} seconds")
        
        print(f"\nüìã Module Details:")
        
        for module in self.test_modules:
            status = "‚úÖ" if module["success"] else "‚ùå"
            exec_time = module.get("execution_time", 0)
            print(f"   {status} {module['description']}: {exec_time:.1f}s")
            
        # Show failures if any
        failed_modules = [m for m in self.test_modules if not m["success"]]
        if failed_modules:
            print(f"\n‚ùå Failed Modules:")
            for module in failed_modules:
                print(f"   ‚Ä¢ {module['description']}")
                if "error" in module:
                    print(f"     Error: {module['error']}")
                elif "stderr" in module and module["stderr"]:
                    error_lines = module["stderr"].strip().split('\n')
                    print(f"     Error: {error_lines[-1]}")  # Show last error line
                    
        # Test coverage summary
        print(f"\nüìà Test Coverage Summary:")
        coverage_areas = [
            "Restaurant Application Submission",
            "Platform Approval Workflow", 
            "User Account Creation",
            "Role-Based User Management",
            "Authentication Testing",
            "Menu Category Creation",
            "Menu Item Creation",
            "Menu Modifier Management",
            "Data Validation & Error Handling",
            "Duplicate Prevention",
            "Permission Enforcement"
        ]
        
        print(f"   Covered Areas: {len(coverage_areas)}")
        for area in coverage_areas:
            print(f"   ‚úÖ {area}")
            
        # Performance insights
        if self.test_modules:
            fastest_module = min(self.test_modules, key=lambda x: x.get("execution_time", float('inf')))
            slowest_module = max(self.test_modules, key=lambda x: x.get("execution_time", 0))
            
            print(f"\n‚ö° Performance Insights:")
            print(f"   Fastest Test: {fastest_module['description']} ({fastest_module.get('execution_time', 0):.1f}s)")
            print(f"   Slowest Test: {slowest_module['description']} ({slowest_module.get('execution_time', 0):.1f}s)")
            
        # Recommendations
        print(f"\nüí° Recommendations:")
        if successful_modules == total_modules:
            print(f"   ‚úÖ All create operations working correctly")
            print(f"   ‚Ä¢ Proceed with update operations testing")
            print(f"   ‚Ä¢ Consider running business workflow tests")
        else:
            print(f"   ‚ö†Ô∏è  Some create operations failed")
            print(f"   ‚Ä¢ Fix failing endpoints before proceeding")
            print(f"   ‚Ä¢ Check authentication and permissions")
            print(f"   ‚Ä¢ Verify database constraints and validation")
            
    async def run_comprehensive_create_tests(self):
        """Run comprehensive create operations testing"""
        
        start_time = time.time()
        
        self.print_header("RMS Comprehensive Create Operations Testing", "‚ûï")
        
        print(f"Target API: {self.base_url}")
        print(f"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # Check API availability first
            self.print_step("Checking API availability", "RUNNING")
            
            async with APITestClient(self.base_url) as client:
                response = await client.get("/health")
                if response.status_code == 200:
                    self.print_step("API is available and healthy", "SUCCESS")
                else:
                    self.print_step(f"API health check failed: HTTP {response.status_code}", "FAILED")
                    print(f"\n‚ùå API is not available. Please start the RMS API server first:")
                    print(f"   uv run uvicorn app.main:app --reload --port 8000")
                    return False
                    
            # Run all create tests
            success = await self.run_all_create_tests()
            
            # Calculate total execution time
            total_time = time.time() - start_time
            self.overall_results.execution_time = total_time
            
            # Print comprehensive summary
            self.print_comprehensive_summary()
            
            return success
            
        except KeyboardInterrupt:
            print(f"\n‚ö†Ô∏è  Testing interrupted by user")
            return False
        except Exception as e:
            print(f"\n‚ùå Testing process failed: {e}")
            return False


async def main():
    """Main entry point for comprehensive create testing"""
    
    import argparse
    
    parser = argparse.ArgumentParser(description="Run all RMS create operation tests")
    parser.add_argument("--base-url", default="http://localhost:8000", help="API base URL")
    
    args = parser.parse_args()
    
    orchestrator = CreateOperationsOrchestrator(args.base_url)
    
    try:
        success = await orchestrator.run_comprehensive_create_tests()
        
        if success:
            print(f"\nüéâ All create operation tests completed successfully!")
            print(f"\nüí° Next steps:")
            print(f"   ‚Ä¢ Run update operations: python ../test_update_operations/run_all_update_tests.py")
            print(f"   ‚Ä¢ Run delete operations: python ../test_delete_operations/run_all_delete_tests.py --confirm-deletes")
            print(f"   ‚Ä¢ Run comprehensive tests: python ../run_comprehensive_tests.py full")
        else:
            print(f"\nüí• Some create operation tests failed")
            print(f"   Review the failures above and fix issues before proceeding")
            sys.exit(1)
            
    except Exception as e:
        print(f"‚ùå Fatal error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())